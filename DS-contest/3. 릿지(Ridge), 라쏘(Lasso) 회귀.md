# 릿지(Ridge), 라쏘(Lasso) 회귀
과적합을 방지하기 위해서는 다양한 방법을 시도할 수 있습니다. 그 중에서도 모델 자체에 정규화가 적용된 방법이 있습니다.

정규화 방법을 적용한 총 3가지(릿지, 라쏘, 엘라스틱 넷) 과적합 방지 모델 중 이번 실습에서는 릿지(Ridge), 라쏘(Lasso) 회귀에 대해 알아보겠습니다.

사이킷런에 구현된 릿지 회귀와 라쏘 회귀를 이용하여 데이터를 학습시키고, ![image](https://user-images.githubusercontent.com/110414297/187682900-ba7a3319-a064-4c48-861e-0978faf84138.png)들의 크기를 확인해보겠습니다.

학습한 릿지, 라쏘 회귀를 활용하여 주가 예측에 적용해보세요.

## 사이킷런 데이터의 변수 이름을 불러오기 위한 방법
```load_boston().feature_names``` : boston 데이터의 변수 이름을 반환합니다.


## 릿지(Ridge), 라쏘(Lasso) 회귀를 위한 사이킷런 라이브러리/함수

```from sklearn.linear_model import Ridge``` : 사이킷런에 저장된 릿지 회귀를 불러옵니다.

```Ridge(alpha)```: 릿지 회귀를 정의합니다.

 - alpha: 기본값은 1입니다.
 - alpha값이 클수록 더 강한 정규화를 적용합니다.

```from sklearn.linear_model import Lasso``` : 사이킷런에 저장된 라쏘 회귀를 불러옵니다.

```Lasso(alpha)```: 라쏘 회귀를 정의합니다.

 - alpha: 기본값은 1입니다.
 - alpha값이 클수록 더 강한 정규화를 적용합니다.

머신러닝 심화 과목에서 추가적인 정규화 회귀인 엘라스틱 넷 회귀에 대해 학습하실 수 있습니다.


## 지시사항

1. 데이터와 변수 이름을 불러오는 load_data() 함수를 구현합니다.
 
2. 릿지 회귀를 구현하고 데이터를 바탕으로 학습시킨 모델을 반환하는 Ridge_regression() 함수를 완성합니다.
 
3. 라쏘 회귀를 구현하고 데이터를 바탕으로 학습시킨 모델을 반환하는 Lasso_regression() 함수를 완성합니다.

4. 실행 버튼을 눌러 릿지 회귀와 라쏘 회귀의 각 변수의 ![image](https://user-images.githubusercontent.com/110414297/187682900-ba7a3319-a064-4c48-861e-0978faf84138.png)값들을 확인하고, 각 회귀의 특징을 이해해봅니다.
 - 그래프를 통해 각 변수들의 ![image](https://user-images.githubusercontent.com/110414297/187682900-ba7a3319-a064-4c48-861e-0978faf84138.png)의 크기를 살펴보고, 라쏘 회귀와 릿지 회귀의 차이점을 생각해보세요.

```python
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

from elice_utils import EliceUtils
elice_utils = EliceUtils()

from sklearn.linear_model import Ridge
from sklearn.linear_model import Lasso

from sklearn.datasets import load_boston

"""
1. 사이킷런에 존재하는 데이터를 불러오고, 
   불러온 데이터를 학습용 데이터와 테스트용 데이터로 
   분리하여 반환하는 함수를 구현합니다.
   
   Step01. 사이킷런에 존재하는 boston 데이터를 
           (X, y)의 형태로 불러옵니다. 
   
   Step02. 데이터의 변수 이름을 feature_names 에
           저장합니다.
"""
def load_data():
    
    X, y = None
    
    feature_names = None
    
    return X,y,feature_names
    
"""
2. 릿지(Ridge) 회귀를 구현하고, 
   전체 데이터를 바탕으로 학습시킨 모델을 
   반환하는 함수를 완성합니다.
   
   Step01. 사이킷런에 구현되어 있는 
           릿지(Ridge) 회귀 모델을 불러옵니다.
           
           파라미터 alpha를 10으로 설정합니다.
   
   Step02. 불러온 모델을 전체 데이터에 맞춰
           학습시킵니다.
"""
def Ridge_regression(X, y):
    
    ridge_reg = None
    
    None
    
    return ridge_reg

"""
2. 라쏘(Lasso) 회귀를 구현하고, 
   전체 데이터를 바탕으로 학습시킨 모델을 
   반환하는 함수를 완성합니다.
   
   Step01. 사이킷런에 구현되어 있는 
           라쏘(Lasso) 회귀 모델을 불러옵니다.
           
           파라미터 alpha를 10으로 설정합니다.
   
   Step02. 불러온 모델을 전체 데이터에 맞춰
           학습시킵니다.
"""
def Lasso_regression(X, y):
    
    lasso_reg = None
    
    None
    
    return lasso_reg
    
# 각 변수의 beta_i 크기를 시각화하는 함수입니다.
def plot_graph(coef, title):
    fig = plt.figure()
    
    plt.ylim(-1,1)
    plt.title(title)
    coef.plot(kind='bar')

    plt.savefig("result.png")
    elice_utils.send_image("result.png")


def main():
    
    X,y,feature_names = load_data()
    
    ridge_reg = Ridge_regression(X, y)
    lasso_reg = Lasso_regression(X, y)
    
    ## Ridge 회귀의 beta_i의 크기를 저장합니다.
    ridge_coef = pd.Series(ridge_reg.coef_, feature_names).sort_values()
    print("Ridge 회귀의 beta_i\n", ridge_coef)
    
    ## Lasso 회귀의 beta_i의 크기를 저장합니다.
    lasso_coef = pd.Series(lasso_reg.coef_, feature_names).sort_values()
    print("Lasso 회귀의 beta_i\n", lasso_coef)
    
    plot_graph(ridge_coef, 'Ridge')
    plot_graph(lasso_coef, 'Lasso')

if __name__=="__main__":
    main()
```
