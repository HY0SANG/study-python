# 과적합 방지 기법 - 교차 검증
주가 데이터를 예측하다보면, 학습 데이터에서는 높은 성능을 보이나, 테스트 데이터에서는 특히 낮은 성능을 보이는 경우가 있습니다.

이러한 현상을 과적합이라고 부르는데요, 과적합을 방지하기 위해서 어떠한 방식을 사용하여야 할 지에 대해 실습을 통해 알아보도록 하겠습니다.


**교차 검증(cross validation)** 은 과적합 방지를 위해 데이터를 분리하는 방법입니다.

기존 실습 문제들에서 학습용 데이터와 테스트용 데이터로 분리하는 방법을 적용하였는데, 이번 실습에서는 테스트 뿐만 아니라 검증용(Validation) 데이터를 활용하여 모델 결과를 평가해보겠습니다.

일반적으로 교차 검증에서 가장 많이 사용되는 것이 바로 **k-fold 교차 검증**입니다.

k-fold 교차 검증은 아래와 같이 학습용 데이터를 계속 변경하며 모델을 훈련시키는 방법입니다.

![image](https://user-images.githubusercontent.com/110414297/187683946-74308dd5-4709-4aef-bcfe-179805abb428.png)

k-fold 교차 검증은 다음과 같은 순서로 진행됩니다.

1. 데이터를 train, test 데이터로 분할
2. K를 설정하여 train 데이터 셋을 K개로 나눔
3. K개 중 한 개를 검증용, 나머지를 학습용으로 사용
4. K개 모델의 평균 성능 확인

## K-fold 교차 검증을 위한 사이킷런 함수/라이브러리

- KFold(n_splits)
  - n_splits : 분리할 데이터(fold) 개수
- [KFold].split(X)
  - 실제로 데이터를 분리하기 위한 인덱스를 반환합니다.
  - X : 분리하고자 하는 데이터
머신러닝 심화 과목에서 과적합 방지를 위한 다양한 방법을 학습하실 수 있습니다.

## 지시사항
1. 사이킷런에 존재하는 데이터를 불러오고, 불러온 데이터를 학습용, 테스트용 데이터로 분리하여 반환하는 ```load_data()``` 함수를 구현합니다.
2. K-fold 교차 검증을 통한 모델 학습 및 예측 수행을 진행하는 ```kfold_regression()``` 함수를 구현합니다.
3. 실행 버튼을 눌러 검증 데이터에 대한 평균 평가 점수를 확인합니다.

## Tips!
각 fold에서 model의 가중치를 동일하게 초기화 하기 위해 model을 정의하는 코드는 k-fold 교차 검증을 수행하는 for문 내부에 위치해있어야 합니다.

```python
import numpy as np

from sklearn.model_selection import train_test_split

from sklearn.datasets import load_boston
from sklearn.linear_model import LinearRegression

# sklearn의 KFold 모듈 불러오기
from sklearn.model_selection import KFold

"""
1. 사이킷런에 존재하는 데이터를 불러오고, 
   불러온 데이터를 학습용 데이터와 테스트용 데이터로 
   분리하여 반환하는 함수를 구현합니다.
   
   Step01. 사이킷런에 존재하는 boston 데이터를 
           (X, y)의 형태로 불러옵니다. 
   
   Step02. 불러온 데이터를 
           학습용 데이터와 테스트용 데이터로
           분리합니다.
           
           학습용 데이터로 전체 데이터의 80%를,
           테스트용 데이터로 나머지 20%를 사용합니다.
           
           동일한 결과 확인을 위하여 random_state를
           100으로 설정합니다.
"""
def load_data():
    
    X, y = None
    
    train_X, test_X, train_y, test_y = None
    
    return train_X, test_X, train_y, test_y
    

"""
2. K-fold 교차 검증을 통한 
   모델 학습 및 예측 수행을 진행할 함수를 구현합니다.
   
   Step01. 전체 데이터를 5개로 분리할 수 있도록 
           KFold 객체를 정의합니다.
           
   Step02. 정의한 kFold 객체와 .split() 함수를 이용하여 
           학습용 데이터 내에서 다시 
           학습용(Train) 데이터와 검증용(Validation)
           데이터를 나누고 
           각각 X_train, X_val, y_train, y_val에
           저장합니다.
           
           train_idx 와 val_idx는 분리된 데이터들의
           인덱스입니다.
            
   Step03. 분리한 학습용 데이터로 모델을 학습시키고,
           검증용 데이터로 모델을 평가하여 
           각 데이터에 대한 모델 평가 점수를 score
           변수에 저장합니다.
"""
def kfold_regression(train_X, train_y):
    
    # 반복문 내에서 횟수를 표시하기 위한 변수 설정하기
    n_iter = 0
    
    # 각 fold 마다 모델 검증 점수를 저장하기 위한 빈 리스트 생성하기
    model_scores = []
    
    kfold = None
    
    for train_idx, val_idx in None:
        
        X_train, X_val =  None, None
        y_train, y_val =  None, None
        
        # 동일한 가중치 사용을 위해 각 fold 마다 모델 초기화 하기
        model = LinearRegression()
        
        None
        
        # 각 Iter 별 모델 평가 점수 측정
        score = None
        
        # 학습용 데이터의 크기를 저장합니다.
        train_size = X_train.shape[0]
        val_size = X_val.shape[0]
    
        print("Iter : {0} Cross-Validation Accuracy : {1}, Train Data 크기 : {2}, Validation Data 크기 : {3}"
              .format(n_iter, score, train_size, val_size))
    
        n_iter += 1
        
        # 전체 모델 점수를 저장하는 리스트에 추가하기
        model_scores.append(score)
        
    return kfold, model, model_scores
        
        
def main():
    
    # 학습용 데이터와 테스트 데이터 불러오기
    train_X, test_X, train_y, test_y = load_data()
    
    # KFold 교차 검증을 통한 학습 결과와 회귀 모델을 반환하는 함수 호출하기
    kfold, model, model_scores = kfold_regression(train_X, train_y)
    
    # 전체 성능 점수의 평균 점수 출력
    print("\n> 평균 검증 모델 점수 : ", np.mean(model_scores))
    

    
if __name__ == "__main__":
    main()

```
